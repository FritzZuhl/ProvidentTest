{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_features = pd.read_csv(\"data_with_features.csv\")\n",
    "#data_features.set_index(data_features['account_id'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_features.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_features.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# XGBoost needs categorical values to be one-hot encoded\n",
    "\n",
    "#loan\n",
    "fico_bins_ds = pd.get_dummies(data_features['fico_bin'], prefix='FICO')\n",
    "# ntriggers_bin\n",
    "ntrigger_bins_df= pd.get_dummies(data_features['ntriggers_bin'], prefix='NTRIGGERS')\n",
    "one_hot_features = fico_bins_ds.join(ntrigger_bins_df)\n",
    "# num_times_neg_bin\n",
    "num_times_neg_bins_df = pd.get_dummies(data_features['num_times_neg_bin'], prefix=\"NUMtimesNEG\")\n",
    "one_hot_features = one_hot_features.join(num_times_neg_bins_df)\n",
    "# max_days_neg_bin\n",
    "max_days_neg_bins_df = pd.get_dummies(data_features['max_days_neg_bin'], prefix=\"MAXdaysNEG\")\n",
    "one_hot_features = one_hot_features.join(max_days_neg_bins_df)\n",
    "# ck_returns_bin\n",
    "ck_returns_bins_df = pd.get_dummies(data_features['ck_returns_bin'], prefix=\"CTRETURNS\")\n",
    "one_hot_features = one_hot_features.join(ck_returns_bins_df)\n",
    "# ave_bal6_binned/ave_bal3_binned\n",
    "aveBal6_bins_df = pd.get_dummies(data_features['avg_bal6_binned'], prefix='AVEBAL6')\n",
    "one_hot_features = one_hot_features.join(aveBal6_bins_df)\n",
    "#\n",
    "aveBal3_bins_df = pd.get_dummies(data_features['avg_bal3_binned'], prefix='AVEBAL3')\n",
    "one_hot_features = one_hot_features.join(aveBal3_bins_df)\n",
    "#\n",
    "print(\"Shape of one-hot features:\", one_hot_features.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Join one-hot features to general dataset.\n",
    "data_features2 = data_features.join(one_hot_features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"size of data_features2:\", data_features2.shape)\n",
    "print(\"Columns in data_features2\", data_features2.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Keep features needed for xg boost model\n",
    "\n",
    "# Drop these columns to prepare data for xgboost\n",
    "drop_columns = ['fico_bin', 'ntriggers_bin', 'num_times_neg_bin', 'max_days_neg_bin', 'ck_returns_bin',\n",
    "                'avg_bal6_binned', 'avg_bal3_binned']\n",
    "drop_columns2 = ['fico_b', 'ntriggers', 'num_times_neg', 'max_days_neg', 'ck_returns', 'avg_bal6', 'avg_bal3'] + drop_columns\n",
    "# optional drop\n",
    "drop_columns3 = ['account_id'] + drop_columns2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "analytic_dataset = data_features2.drop(drop_columns2, axis=1)\n",
    "print(analytic_dataset.shape)\n",
    "\n",
    "# inspect using Excel - did it go okay?\n",
    "analytic_dataset.to_csv(\"analytic_dataset.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The story so far...\n",
    "The data from Step 1, EDA and Feature Extraction phase, was read into Python. All of the categorical features had to be converted into one-hot encoding, since XGboost work best with numerical data.\n",
    "After the one-hot encoded features were added to the analytical dataset, many of the original fields need to be removed before submitting to XGboost."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What to do next...\n",
    "1. split data into charged-off data\n",
    "2. select 20% of the active accounts for training.\n",
    "3. prepare XGboost for imbalanced data\n",
    "4. run XGboost\n",
    "5. score active accounts for propensity to defraud\n",
    "6. print out decision tree\n",
    "7. print out features, and their relative importance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1.Split data into charged-off and non charged-off.\n",
    "# Since the objective of the model is to identify accounts that are most likely to commit fraudulent activities,\n",
    "# we will select accounts that are active.\n",
    "active_accounts = analytic_dataset[analytic_dataset['status']=='Active']\n",
    "data_CO = analytic_dataset[analytic_dataset['cos']==1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tmp = pd.concat([\"active_accounts\", \"data_CO\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Active accounts shape:\",active_accounts.shape)\n",
    "print(\"Charged-off accounts shape:\", data_CO.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Randomly select 20% of non-charged off accounts\n",
    "np.random.seed(147)\n",
    "active_accounts_frac20 = active_accounts.sample(frac=0.2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "active_accounts_frac20.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(active_accounts_frac20.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For training set, add the 20%-sample of active accounts with all of the charged-off accounts.\n",
    "analytic_dataset_model = active_accounts_frac20.join(data_CO)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# xg_reg = xgb.XGBRegressor(objective='reg:linear', colsample_bytree=0.3, learning_rate=0.1,\n",
    "#                           max_depth=5, alpha=10, n_estimators=10)\n",
    "#\n",
    "# params = {\"objective\": \"binary:logistic\", 'colsample_bytree': 0.3, 'learning_rate': 0.1,\n",
    "#           'max_depth': 5, 'alpha': 10}\n",
    "#\n",
    "# cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "#                     num_boost_round=50, early_stopping_rounds=10, metrics=\"rmse\", as_pandas=True, seed=123)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}